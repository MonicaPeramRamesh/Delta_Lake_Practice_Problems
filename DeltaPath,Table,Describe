from pyspark.sql.types import *
from pyspark.sql.functions import *

df.write.format("delta").saveAsTable("delta_practice_catalog.test_schema.sales")

#Read delta table thorugh path
df = spark.read.format("delta").option("header",True).load("/Volumes/delta_practice_catalog/test_schema/users/sales/")
display(df)

#Read delta table thorugh table
%sql
select * from delta_practice_catalog.test_schema.sales

# Describe delta table detail using delta path
%sql
describe detail  delta.`/Volumes/delta_practice_catalog/test_schema/users/sales/`

# Describe delta table detail using delta table
%sql
describe detail delta_practice_catalog.test_schema.sales
